{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c140aa",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "**Question**\n",
    "\n",
    "* Why do we need attention mechanism?\n",
    "* Why do we need sqrt(d_k) in denominator (self attention formula)?\n",
    "    * Keep the numbers (KQ^{T}) on the right scale\n",
    "* Why do we need Masking?\n",
    "    * Helps the model do not cheat (by looking words in the future)\n",
    "    * we don't need in the enconders, just in the decoders\n",
    "\n",
    "**Huh**\n",
    "\n",
    "* [Truncated Backpropagation](https://arxiv.org/abs/1705.08209) \n",
    "* BRNN\n",
    "\n",
    "**Aha**\n",
    "\n",
    "* RNNs are slow, since we need to feed one token at time\n",
    "* The encoder transform input vectors in high quality vectors (by context)\n",
    "* Vectors: \n",
    "    * Q => What I am looking for\n",
    "    * K => What I can offrer\n",
    "    * V => What I actually offer\n",
    "* Softmax transforms a Vector intro a Probability Distribution\n",
    "* Multi-Head Attention => Stack Attention mechanism\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b57dfa",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d6c47e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38061eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "L, d_k, d_v = 4, 8, 8\n",
    "\n",
    "q = np.random.randn(L, d_k)\n",
    "k = np.random.randn(L, d_k)\n",
    "v = np.random.randn(L, d_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b457a9ec",
   "metadata": {},
   "source": [
    "\n",
    "* (Aha) L => length of input sequence (e.g My name is..)\n",
    "\n",
    "\n",
    "* (Huh) what's d_k and d_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6442bf53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.28849593, -7.23187435,  3.43074998, -0.92817642],\n",
       "       [-5.87109603,  5.42403214, -3.432637  , -2.45887263],\n",
       "       [-3.17989029,  1.62472654, -5.05057619,  4.4481915 ],\n",
       "       [ 0.12658553, -3.83293587, -0.74856257, -6.26228145]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(q, k.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98352c6f",
   "metadata": {},
   "source": [
    "* (huh) what matmul does?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46599bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(1.7088368202136353),\n",
       " np.float64(0.9332648496490006),\n",
       " np.float64(18.435487410675933),\n",
       " np.float64(6.517929081284088))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var(), k.var(), np.matmul(q, k.T).var(), np.matmul(q, k.T).var() / math.sqrt(d_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed823a4",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6f57204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.tril(np.ones((L, L)))\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6326c743",
   "metadata": {},
   "source": [
    "* (Huh) what's a triagular matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8aa2f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[mask == 0] = -np.inf\n",
    "mask[mask == 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e265a6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.51792908,       -inf,       -inf,       -inf],\n",
       "       [6.51792908, 6.51792908,       -inf,       -inf],\n",
       "       [6.51792908, 6.51792908, 6.51792908,       -inf],\n",
       "       [6.51792908, 6.51792908, 6.51792908, 6.51792908]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled = np.matmul(q, k.T).var() / math.sqrt(d_k)\n",
    "scaled + mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372e4c55",
   "metadata": {},
   "source": [
    "* (Aha) -inf means \"no context for you buddy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93b8dfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax x\n",
      "[[0.31975761 0.68024239]\n",
      " [0.22497968 0.77502032]\n",
      " [0.07906715 0.92093285]\n",
      " [0.35108277 0.64891723]\n",
      " [0.51068233 0.48931767]\n",
      " [0.22200682 0.77799318]\n",
      " [0.80085823 0.19914177]\n",
      " [0.48678087 0.51321913]\n",
      " [0.17752741 0.82247259]\n",
      " [0.30979596 0.69020404]]\n",
      "\n",
      "\n",
      "x\n",
      "[[ 0.4259755   1.18086143]\n",
      " [-1.47609278 -0.23921365]\n",
      " [-1.06771174  1.38737794]\n",
      " [-0.86724152 -0.25295836]\n",
      " [ 0.04656291  0.00382708]\n",
      " [-0.65384737  0.60016231]\n",
      " [-0.16581249 -1.55747948]\n",
      " [ 0.11699794  0.16988679]\n",
      " [ 0.17420282  1.70739294]\n",
      " [-0.82380603 -0.02273263]]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T\n",
    "\n",
    "x = np.random.randn(10, 2)\n",
    "\n",
    "print(\"softmax x\")\n",
    "print(f\"{softmax(x)}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"x\")\n",
    "print(f\"{x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00074a9c",
   "metadata": {},
   "source": [
    "* (aha) In the softmax version, each rows add to one (because it's a probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00e07048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 0.5       , 0.        , 0.        ],\n",
       "       [0.33333333, 0.33333333, 0.33333333, 0.        ],\n",
       "       [0.25      , 0.25      , 0.25      , 0.25      ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = softmax(scaled + mask)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45fe543d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.16871155, -0.78041098,  0.25572825,  0.73675932, -0.3480004 ,\n",
       "        -0.56011948, -0.53965195, -0.67495813],\n",
       "       [-0.62182327, -0.16760881,  0.06496911, -0.13564645, -0.79712902,\n",
       "         0.50635758,  0.0850759 , -0.65417167],\n",
       "       [-0.30656334,  0.23549939, -0.22881219,  0.09043942, -0.5740131 ,\n",
       "         0.48148352, -0.27546704, -0.31740677],\n",
       "       [-0.14594315,  0.16658348, -0.02133608, -0.26571102,  0.00498718,\n",
       "         0.371516  ,  0.24024852, -0.57709043]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_v = np.matmul(attention, v)\n",
    "new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd00d562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.16871155, -0.78041098,  0.25572825,  0.73675932, -0.3480004 ,\n",
       "        -0.56011948, -0.53965195, -0.67495813],\n",
       "       [ 0.92506501,  0.44519336, -0.12579003, -1.00805221, -1.24625765,\n",
       "         1.57283464,  0.70980376, -0.63338521],\n",
       "       [ 0.32395651,  1.04171578, -0.81637479,  0.54261115, -0.12778125,\n",
       "         0.43173541, -0.99655292,  0.35612303],\n",
       "       [ 0.33591742, -0.04016425,  0.60109226, -1.33416232,  1.74198804,\n",
       "         0.04161343,  1.78739519, -1.35614143]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
